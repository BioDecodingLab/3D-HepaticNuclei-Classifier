# -*- coding: utf-8 -*-
"""3_training_classifiers_Random_Forest.ipynt.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QKyanDm-d_JdJDhrnaYo1PxoSKVNmVsF
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    accuracy_score,
    classification_report,
    confusion_matrix,
    ConfusionMatrixDisplay,
    precision_recall_fscore_support
)

from scipy.stats import randint

#Rutas de los embeddings
TRAIN_EMB_PATH = "/content/drive/MyDrive/tesis/embeddings_3dino_TRAIN_aug10k_seed42_finn.npz"
TEST_EMB_PATH  = "/content/drive/MyDrive/tesis/embeddings_3dino_TEST_seed42_fin.npz"

VAL_SIZE = 0.10   # 90/10
RANDOM_STATE = 42

# Carga de embeddings guardados en .npz
def load_npz_embeddings(path):
    data = np.load(path, allow_pickle=True)
    print(f"\nArchivo: {path}")
    print("Keys encontradas:", list(data.keys()))


    if "X" in data and "y" in data:
        X, y = data["X"], data["y"]
    elif "embeddings" in data and "labels" in data:
        X, y = data["embeddings"], data["labels"]
    else:
        raise ValueError("No encuentro las llaves X/y o embeddings/labels.")

    X = np.asarray(X)
    y = np.asarray(y).reshape(-1).astype(int)
    return X, y

# Carga embeddings y etiquetas del conjunto de entrenamiento
X_train_full, y_train_full = load_npz_embeddings(TRAIN_EMB_PATH)
# Carga embeddings y etiquetas del conjunto de prueba
X_test, y_test = load_npz_embeddings(TEST_EMB_PATH)

print("\nResumen:")
print("Train:", X_train_full.shape, np.unique(y_train_full, return_counts=True))
print("Test :", X_test.shape, np.unique(y_test, return_counts=True))

# Divide el conjunto de entrenamiento en Train y Validation
# - test_size define el porcentaje que se reserva para validación
# - stratify mantiene la misma proporción de clases en ambos conjuntos
# - random_state fija la aleatoriedad para que el split sea reproducible
X_train, X_val, y_train, y_val = train_test_split(
    X_train_full,
    y_train_full,
    test_size=VAL_SIZE,
    random_state=RANDOM_STATE,
    stratify=y_train_full
)

print("Train:", X_train.shape)
print("Val  :", X_val.shape)

# Evalúa un modelo de clasificación y muestra métricas + reportes + matrices de confusión
def evaluate_model(model, X, y, title=""):
    y_pred = model.predict(X)

    acc = accuracy_score(y, y_pred)
    pr_m, rc_m, f1_m, _ = precision_recall_fscore_support(
        y, y_pred, average="macro", zero_division=0
    )
    pr_w, rc_w, f1_w, _ = precision_recall_fscore_support(
        y, y_pred, average="weighted", zero_division=0
    )

    print(f"\n===== {title} =====")
    print(f"Accuracy: {acc:.6f}")
    print(f"Macro    -> Precision: {pr_m:.6f} | Recall: {rc_m:.6f} | F1: {f1_m:.6f}")
    print(f"Weighted -> Precision: {pr_w:.6f} | Recall: {rc_w:.6f} | F1: {f1_w:.6f}")
    print("\nClassification report:")
    print(classification_report(y, y_pred, digits=6, zero_division=0))

    # Matriz de confusión (conteos)
    cm = confusion_matrix(y, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm)
    disp.plot(values_format="d")
    plt.title(f"Confusion Matrix – {title}")
    plt.show()

    # Matriz de confusión normalizada
    cmn = confusion_matrix(y, y_pred, normalize="true")
    disp2 = ConfusionMatrixDisplay(confusion_matrix=cmn)
    disp2.plot(values_format=".2f")
    plt.title(f"Confusion Matrix Normalizada – {title}")
    plt.show()

    return y_pred

# Modelo baseline: Random Forest
rf_base = RandomForestClassifier(
    n_estimators=800,
    random_state=RANDOM_STATE,
    n_jobs=-1,
    class_weight="balanced_subsample"
)

# Entrena el modelo con el conjunto de entrenamiento
rf_base.fit(X_train, y_train)

_ = evaluate_model(rf_base, X_val, y_val, "VALIDACIÓN (RF base)")
_ = evaluate_model(rf_base, X_test, y_test, "TEST (RF base)")

from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier

# Espacio de búsqueda de hiperparámetros para Random Forest
param_dist_ultra = {
    "n_estimators": [150, 250, 350, 450],
    "max_depth": [20, 30, 40, None],
    "min_samples_split": [2, 5, 10],
    "min_samples_leaf": [1, 2, 4],
    "max_features": ["sqrt", "log2"],
    "bootstrap": [True],
    "class_weight": ["balanced_subsample"]
}

# Validación cruzada estratificada:
# Mantiene proporciones de clases en cada fold y mezcla el orden para mayor robustez
cv_ultra = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)

# Búsqueda aleatoria de hiperparámetros:
# Prueba n_iter combinaciones aleatorias dentro del espacio definido y elige la mejor según f1_macro
search = RandomizedSearchCV(
search = RandomizedSearchCV(
    estimator=RandomForestClassifier(
        random_state=RANDOM_STATE,
        n_jobs=-1,
        max_samples=0.7
    ),
    param_distributions=param_dist_ultra,
    n_iter=10,            # 10 candidatos -> 10*3 = 30 fits
    scoring="f1_macro",
    cv=cv_ultra,
    random_state=RANDOM_STATE,
    n_jobs=1,
    verbose=2
)

search.fit(X_train_full, y_train_full)

print("\nBest params:", search.best_params_)
print("Best CV f1_macro:", search.best_score_)

# Obtiene el mejor modelo encontrado por RandomizedSearchCV
best_rf = search.best_estimator_

# Entrena el modelo optimizado solo con X_train para comparar de forma justa contra el baseline
best_rf.fit(X_train, y_train)
# Evalúa en el conjunto de validación (sirve para comparar configuraciones sin tocar el test)
_ = evaluate_model(best_rf, X_val, y_val, "VALIDACIÓN (RF optimizado)")

# Entrenamiento final para reporte
best_rf.fit(X_train_full, y_train_full)
_ = evaluate_model(best_rf, X_test, y_test, "TEST (RF optimizado, entrenado con todo TRAIN)")