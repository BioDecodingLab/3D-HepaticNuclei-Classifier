# -*- coding: utf-8 -*-
"""Copia de  DINO preentrenado 3500 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y84rq3G9h3bBACyZmv1k2cNwa17la4o-
"""

#!git clone https://github.com/AICONSlab/3DINO.git

from google.colab import drive
drive.mount('/content/drive')

!pip install -r /content/drive/MyDrive/tesis/3DINO-main/3DINO-main/requirements.txt

import os, glob, random
import numpy as np
import torch
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import tifffile as tiff
import matplotlib.pyplot as plt
import skimage

SEED = 42

def seed_everything(seed=SEED):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

seed_everything(SEED)

TRAIN_DIR = "/content/drive/MyDrive/tesis/patches_train"
TEST_DIR  = "/content/drive/MyDrive/tesis/patches_test"

LABELS = [1,2,3,4,5]
TARGET_DHW0 = (80,80,80)
TARGET_DHW  = (112,112,112)

BATCH_SIZE = 8
NUM_WORKERS = 2
TARGET_PER_LABEL = 3500

AUG_VIZ_DIR = "/content/drive/MyDrive/tesis/aug_viz_examples_crop_3500_solocrop_2"
os.makedirs(AUG_VIZ_DIR, exist_ok=True)

def normalize_to_minus1_1(vol, p_low=0.0005, p_high=0.9995):
    vol = vol.astype(np.float32)
    lo = np.quantile(vol, p_low)
    hi = np.quantile(vol, p_high)
    vol = (vol - lo) / (hi - lo + 1e-8)
    vol = np.clip(vol * 2 - 1, -1, 1)
    #vol = np.clip(vol, 0, 1)
    return vol

def center_crop_or_pad_3d(vol, target_dhw):
    D,H,W = vol.shape
    tD,tH,tW = target_dhw
    pad_d = max(0, tD - D); pad_h = max(0, tH - H); pad_w = max(0, tW - W)

    if pad_d or pad_h or pad_w:
        vol = np.pad(
            vol,
            ((pad_d//2, pad_d - pad_d//2),
             (pad_h//2, pad_h - pad_h//2),
             (pad_w//2, pad_w - pad_w//2)),
            mode="constant",
            constant_values=float(vol.min())
        )

    D,H,W = vol.shape
    sD = (D - tD)//2
    sH = (H - tH)//2
    sW = (W - tW)//2
    return vol[sD:sD+tD, sH:sH+tH, sW:sW+tW]

def random_flip_rot(vol, rng: np.random.RandomState):
    if rng.rand() < 0.5: vol = vol[::-1, :, :]
    if rng.rand() < 0.5: vol = vol[:, ::-1, :]
    if rng.rand() < 0.5: vol = vol[:, :, ::-1]
    k = int(rng.randint(0, 4))
    vol = np.rot90(vol, k=k, axes=(1, 2))
    return vol.copy()

def intensity_aug(vol, rng: np.random.RandomState):
    if rng.rand() < 0.8:
        scale = 1.0 + rng.uniform(-0.2, 0.2)
        shift = rng.uniform(-0.1, 0.1)
        vol = np.clip(vol * scale + shift, -1, 1)
    if rng.rand() < 0.5:
        vol = np.clip(vol + rng.normal(0, 0.03, size=vol.shape).astype(np.float32), -1, 1)
    return vol
def gaussian_noise(vol, rng: np.random.RandomState, p=0.5, sigma=0.03):
    if rng.rand() < p:
        vol = np.clip(vol + rng.normal(0, sigma, size=vol.shape).astype(np.float32), -1, 1)
    return vol

def _gaussian_1d_kernel(sigma: float, radius: int):
    x = torch.arange(-radius, radius+1, dtype=torch.float32)
    k = torch.exp(-(x**2) / (2*sigma*sigma))
    k = k / (k.sum() + 1e-8)
    return k

def gaussian_blur_3d(vol, rng: np.random.RandomState, p=0.5, sigma_range=(0.4, 1.2)):
    """
    Blur 3D usando conv3d separable en PyTorch.
    Entrada: vol numpy (D,H,W) float32 [-1,1]
    Salida: vol numpy (D,H,W) float32 [-1,1]
    """
    if rng.rand() >= p:
        return vol

    sigma = float(rng.uniform(sigma_range[0], sigma_range[1]))
    radius = int(max(1, round(3*sigma)))
    k1 = _gaussian_1d_kernel(sigma, radius)  # (K,)

    # Convertir a tensor (1,1,D,H,W)
    x = torch.from_numpy(vol).unsqueeze(0).unsqueeze(0)  # CPU
    x = x.to(torch.float32)

    # kernels separables: aplicar en W, luego H, luego D
    # conv3d  (out_ch,in_ch,kD,kH,kW)
    kW = k1.view(1,1,1,1,-1)
    kH = k1.view(1,1,1,-1,1)
    kD = k1.view(1,1,-1,1,1)

    x = F.conv3d(x, kW, padding=(0,0,radius))
    x = F.conv3d(x, kH, padding=(0,radius,0))
    x = F.conv3d(x, kD, padding=(radius,0,0))

    out = x.squeeze(0).squeeze(0).numpy()
    out = np.clip(out, -1, 1)
    return out.astype(np.float32)

def augment_one(vol, rng: np.random.RandomState):
    # geom
    vol = random_flip_rot(vol, rng)

    # fotométrico
    vol = intensity_aug(vol, rng)

    # blur + noise
    vol = gaussian_blur_3d(vol, rng, p=0.5, sigma_range=(0.4, 1.2))
    vol = gaussian_noise(vol, rng, p=0.5, sigma=0.03)

    return vol
#aumentar el gaussion blur y noice, visualizar las aumentaciones de 20 imagenes y abro en fiji, hacer los embedings sin aumetnar datos, 500, 3500 y 7000 , solo en el random forest primero

class Tif3DDatasetSingle(Dataset):
    def __init__(self, base_dir, labels, target_dhw, do_aug=False, seed=SEED):
        self.items = []
        self.target_dhw = target_dhw
        #self.target_dhw0 = target_dhw0
        self.do_aug = do_aug
        self.seed = seed

        for lv in labels:
            folder = os.path.join(base_dir, f"label_{lv}")
            files = sorted(glob.glob(os.path.join(folder, "*.tif")) + glob.glob(os.path.join(folder, "*.tiff")))
            self.items.extend([(f, lv) for f in files])

    def __len__(self):
        return len(self.items)

    def __getitem__(self, idx):
        path, y = self.items[idx]
        vol = tiff.imread(path).astype(np.float32)  # esperado (Z,H,W)

        vol = normalize_to_minus1_1(vol)
        # clave: NO np.resize; solo "lienzo" 112³ sin deformar, el cambio vs el original de np.resize
        print("original", vol.shape)
        vol = center_crop_or_pad_3d(vol, self.target_dhw)
        #print("padd", vol.shape)
        #vol = skimage.transform.resize(vol, self.target_dhw, order=3)
        #print("scale", vol.shape)


        if self.do_aug:
            rng = np.random.RandomState(self.seed + idx)
            vol = augment_one(vol, rng)

        x = torch.from_numpy(vol).unsqueeze(0)  # (1,D,H,W)
        return x, int(y), path

def build_augmented_index(items, labels, target_per_label, seed=SEED):
    rng = random.Random(seed)
    by_label = {lv: [] for lv in labels}
    for p, y in items:
        by_label[y].append((p, y))

    new_items = []
    for lv in labels:
        src = by_label[lv]
        if len(src) == 0:
            raise ValueError(f"No hay archivos en label_{lv}")
        for _ in range(target_per_label):
            new_items.append(rng.choice(src))
    rng.shuffle(new_items)
    return new_items

def save_aug_preview(dataset_noaug, dataset_aug, n_examples=10, out_dir=AUG_VIZ_DIR):
    """
    Guarda comparaciones (original vs aug) como PNG usando 3 cortes 2D:
    - axial (D/2)
    - coronal (H/2)
    - sagittal (W/2)
    """
    os.makedirs(out_dir, exist_ok=True)

    picks = np.linspace(0, len(dataset_noaug)-1, num=min(n_examples, len(dataset_noaug)), dtype=int)

    for i, idx in enumerate(picks):
        x0, y0, p0 = dataset_noaug[idx]
        x1, y1, p1 = dataset_aug[idx]



        v0 = x0.squeeze(0).numpy()  # (D,H,W)
        v1 = x1.squeeze(0).numpy()

        tiff.imwrite(os.path.join(out_dir,f"noaug_{i:02d}_label{y0}.tif"), v0)
        tiff.imwrite(os.path.join(out_dir,f"aug_{i:02d}_label{y0}.tif"), v1)


        D,H,W = v0.shape
        d0, h0, w0 = D//2, H//2, W//2

        fig, axes = plt.subplots(2, 3, figsize=(12, 8))
        fig.suptitle(f"Label={y0} | idx={idx}\n{os.path.basename(p0)}", fontsize=10)

        # Original
        axes[0,0].imshow(v0[d0,:,:], cmap="gray"); axes[0,0].set_title("Orig axial")
        axes[0,1].imshow(v0[:,h0,:], cmap="gray"); axes[0,1].set_title("Orig coronal")
        axes[0,2].imshow(v0[:,:,w0], cmap="gray"); axes[0,2].set_title("Orig sagittal")

        # Aug
        axes[1,0].imshow(v1[d0,:,:], cmap="gray"); axes[1,0].set_title("Aug axial")
        axes[1,1].imshow(v1[:,h0,:], cmap="gray"); axes[1,1].set_title("Aug coronal")
        axes[1,2].imshow(v1[:,:,w0], cmap="gray"); axes[1,2].set_title("Aug sagittal")

        for ax in axes.ravel():
            ax.axis("off")

        out_path = os.path.join(out_dir, f"aug_preview_{i:02d}_label{y0}.png")
        plt.tight_layout()
        plt.savefig(out_path, dpi=160)
        plt.close(fig)

    print(f" Guardé {len(picks)} previews en: {out_dir}")

cd /content/drive/MyDrive/tesis/3DINO-main/3DINO-main

from dinov2.eval.setup import build_model_for_eval
from dinov2.configs import load_and_merge_config_3d


config_file = "/content/drive/MyDrive/tesis/3DINO-main/3DINO-main/dinov2/configs/train/vit3d_highres"
pretrained_weights = "/content/drive/MyDrive/tesis/3dino_vit_weights.pth"

cfg = load_and_merge_config_3d(config_file)
model = build_model_for_eval(cfg, pretrained_weights)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)
model.eval()

print("Modelo listo en:", device)

def seed_worker(worker_id):
    worker_seed = SEED + worker_id
    np.random.seed(worker_seed)
    random.seed(worker_seed)

g = torch.Generator()
g.manual_seed(SEED)

def extract_embeddings(dataset, save_path):
    loader = DataLoader(
        dataset,
        batch_size=BATCH_SIZE,
        shuffle=False,
        num_workers=NUM_WORKERS,
        pin_memory=True,
        worker_init_fn=seed_worker,
        generator=g
    )

    all_emb, all_y, all_paths = [], [], []

    with torch.no_grad():
        for x, y, paths in loader:
            x = x.to(device, non_blocking=True)
            out = model(x)  # (B,1024) típico
            all_emb.append(out.detach().cpu().numpy())
            all_y.append(np.asarray(y))
            all_paths.extend(list(paths))

    embeddings = np.concatenate(all_emb, axis=0)
    labels = np.concatenate(all_y, axis=0)

    np.savez_compressed(
        save_path,
        embeddings=embeddings,
        labels=labels,
        paths=np.array(all_paths, dtype=object)
    )

    print("Guardado:", save_path)
    print("Embeddings:", embeddings.shape, "| Labels:", labels.shape)
    return embeddings, labels

base_train = Tif3DDatasetSingle(TRAIN_DIR, LABELS, TARGET_DHW, do_aug=False, seed=SEED)
print("Train reales:", len(base_train))

aug_items = build_augmented_index(base_train.items, LABELS, TARGET_PER_LABEL, seed=SEED)

train_aug = Tif3DDatasetSingle(TRAIN_DIR, LABELS, TARGET_DHW, do_aug=True, seed=SEED)
train_aug.items = aug_items

print("Train balanceado:", len(train_aug), f"(= {len(LABELS)} * {TARGET_PER_LABEL})")

save_aug_preview(
    dataset_noaug=base_train,
    dataset_aug=Tif3DDatasetSingle(TRAIN_DIR, LABELS, TARGET_DHW, do_aug=True, seed=SEED),
    n_examples=2,
    out_dir=AUG_VIZ_DIR
)

save_train = "/content/drive/MyDrive/tesis/embeddings_3dino_TRAIN_aug3500_seed42_crop_2.npz"
train_embeddings, train_labels = extract_embeddings(train_aug, save_train)

test_ds = Tif3DDatasetSingle(TEST_DIR, LABELS, TARGET_DHW, do_aug=False, seed=SEED)
print("Test reales:", len(test_ds))

save_test = "/content/drive/MyDrive/tesis/embeddings_3dino_TEST_seed42_112crop_norm_crop_2.npz"
test_embeddings, test_labels = extract_embeddings(test_ds, save_test)